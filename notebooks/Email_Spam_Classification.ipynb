{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Intrducció\n",
    "L'spam o correu no sol·licitat, és una de les amenaces més perilloses que volten en el futur de la societat de la informació.\n",
    "\n",
    "Aquest correu no sol·licitat és una gran eina pel món publicitari degut al baix cost i gran abast que proporcionen els serveis de missatgeria online. No obstant el creixement de l'spam és una amenaça a la convivència i a l'eficàcia dels correus electrònics, és per això que les grans distribuïdores de correus electrònics ja han realitzat algoritmes que permeten classificar aquest tipus de correu i emmagatzemar-lo a la carpeta d'spam per tal de facilitar l'ús del correu als seus usuaris i millorar la seva experiència.\n",
    "\n",
    "![image info](https://scontent-mad1-1.xx.fbcdn.net/v/t1.6435-9/66518471_1296381087186397_6551382846613749760_n.png?_nc_cat=104&ccb=1-5&_nc_sid=9267fe&_nc_ohc=UuU7no3n1CgAX-gyEFe&_nc_ht=scontent-mad1-1.xx&oh=d12b60033a57b7aa4d62a5a66d0a26ec&oe=61D7A24D)\n",
    "\n",
    "\n",
    "En aquest notebook realitzarem un anàlisi del dataset [Email Spam Classification](https://www.kaggle.com/balaka18/email-spam-classification-dataset-csv) de la plataforma [Kaggle](https://www.kaggle.com/kaggle) i intentarem classificar de manera automàtica mitjançant machine learning els correus spam que es troben dins del dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dependències"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score,mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem utilitzat les següents llibreries:\n",
    "- **Pandas:** Ens ajuda a tractar les dades.\n",
    "- **Wanings:** Ens permet eliminar els warnings.\n",
    "- **Matplotlib:** Ens permet realitzar gràfiques.\n",
    "- **Seaborn:** Ens permet realitzar gràfiques.\n",
    "- **Sklearn:** Ens permet entrenar els diferents models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminem gràcies a la llibreria warnings tots els possibles warnings que puguin apareixer en el codi, de tal forma que ens quedi el notebook molt més net i més entenedor per al lector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Realitzarem un estudi del nostre dataset, veurem el numero d'atributs que conté, el nùmero de mostres, el número de valors nuls i apart també veurem el tipus de variables dels nostres atributs i aixi podrem entendre una mica millor el nostre dataset i veure quines seran les variables predictores i quina la nostre variable objectiu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'emails:  5172\n",
      "Nombre d'atributs per cada email:  3002\n",
      "Nombre de valors Nulls:  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\data\\emails.csv\")\n",
    "print(\"Nombre d'emails: \", df.shape[0])\n",
    "print(\"Nombre d'atributs per cada email: \", df.shape[1])\n",
    "print(\"Nombre de valors Nulls: \",df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou     ...      connevey  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0     ...             0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27     ...             0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0     ...             0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10     ...             0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9     ...             0   \n",
       "\n",
       "   jay  valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0    0       0    0               0         0         0   0    0           0  \n",
       "1    0       0    0               0         0         0   1    0           0  \n",
       "2    0       0    0               0         0         0   0    0           0  \n",
       "3    0       0    0               0         0         0   0    0           0  \n",
       "4    0       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.640565</td>\n",
       "      <td>6.188128</td>\n",
       "      <td>5.143852</td>\n",
       "      <td>3.075599</td>\n",
       "      <td>3.124710</td>\n",
       "      <td>2.627030</td>\n",
       "      <td>55.517401</td>\n",
       "      <td>2.466551</td>\n",
       "      <td>2.024362</td>\n",
       "      <td>10.600155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.012568</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.098028</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.914733</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.290023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.745009</td>\n",
       "      <td>9.534576</td>\n",
       "      <td>14.101142</td>\n",
       "      <td>6.045970</td>\n",
       "      <td>4.680522</td>\n",
       "      <td>6.229845</td>\n",
       "      <td>87.574172</td>\n",
       "      <td>4.314444</td>\n",
       "      <td>6.967878</td>\n",
       "      <td>19.281892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.199682</td>\n",
       "      <td>0.116693</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.096252</td>\n",
       "      <td>0.138908</td>\n",
       "      <td>0.072145</td>\n",
       "      <td>2.780203</td>\n",
       "      <td>0.098086</td>\n",
       "      <td>0.453817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1898.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               the           to          ect          and          for  \\\n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000  5172.000000   \n",
       "mean      6.640565     6.188128     5.143852     3.075599     3.124710   \n",
       "std      11.745009     9.534576    14.101142     6.045970     4.680522   \n",
       "min       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "50%       3.000000     3.000000     1.000000     1.000000     2.000000   \n",
       "75%       8.000000     7.000000     4.000000     3.000000     4.000000   \n",
       "max     210.000000   132.000000   344.000000    89.000000    47.000000   \n",
       "\n",
       "                of            a          you          hou           in  \\\n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000  5172.000000   \n",
       "mean      2.627030    55.517401     2.466551     2.024362    10.600155   \n",
       "std       6.229845    87.574172     4.314444     6.967878    19.281892   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000    12.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000    28.000000     1.000000     0.000000     5.000000   \n",
       "75%       2.000000    62.250000     3.000000     1.000000    12.000000   \n",
       "max      77.000000  1898.000000    70.000000   167.000000   223.000000   \n",
       "\n",
       "          ...          connevey          jay       valued          lay  \\\n",
       "count     ...       5172.000000  5172.000000  5172.000000  5172.000000   \n",
       "mean      ...          0.005027     0.012568     0.010634     0.098028   \n",
       "std       ...          0.105788     0.199682     0.116693     0.569532   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          4.000000     7.000000     2.000000    12.000000   \n",
       "\n",
       "       infrastructure     military     allowing           ff          dry  \\\n",
       "count     5172.000000  5172.000000  5172.000000  5172.000000  5172.000000   \n",
       "mean         0.004254     0.006574     0.004060     0.914733     0.006961   \n",
       "std          0.096252     0.138908     0.072145     2.780203     0.098086   \n",
       "min          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%          0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max          3.000000     4.000000     3.000000   114.000000     4.000000   \n",
       "\n",
       "        Prediction  \n",
       "count  5172.000000  \n",
       "mean      0.290023  \n",
       "std       0.453817  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 3001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Columns: 3002 entries, Email No. to Prediction\n",
      "dtypes: int64(3001), object(1)\n",
      "memory usage: 118.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vegades que apareix cada paraula entre tots els emails: \n",
      "\n",
      "the                34345\n",
      "to                 32005\n",
      "ect                26604\n",
      "and                15907\n",
      "for                16161\n",
      "of                 13587\n",
      "a                 287136\n",
      "you                12757\n",
      "hou                10470\n",
      "in                 54824\n",
      "on                 56560\n",
      "is                 27857\n",
      "this                7182\n",
      "enron               6906\n",
      "i                 237177\n",
      "be                 16702\n",
      "that                4781\n",
      "will                4401\n",
      "have                4162\n",
      "with                4860\n",
      "your                4212\n",
      "at                 35854\n",
      "we                 10234\n",
      "s                 216251\n",
      "are                 7285\n",
      "it                 23280\n",
      "by                  3400\n",
      "com                 9140\n",
      "as                 24864\n",
      "from                4210\n",
      "                   ...  \n",
      "decisions             21\n",
      "produced              28\n",
      "ended                366\n",
      "greatest              21\n",
      "degree                45\n",
      "solmonson             32\n",
      "imbalances            30\n",
      "fall                  89\n",
      "fear                  33\n",
      "hate                  82\n",
      "fight                 30\n",
      "reallocated           24\n",
      "debt                  33\n",
      "reform                26\n",
      "australia             36\n",
      "plain                194\n",
      "prompt                46\n",
      "remains               21\n",
      "ifhsc                 27\n",
      "enhancements          29\n",
      "connevey              26\n",
      "jay                   65\n",
      "valued                55\n",
      "lay                  507\n",
      "infrastructure        22\n",
      "military              34\n",
      "allowing              21\n",
      "ff                  4731\n",
      "dry                   36\n",
      "Prediction          1500\n",
      "Length: 3001, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sums = df.iloc[:, 1:].sum(axis=0)\n",
    "print(\"Numero de vegades que apareix cada paraula entre tots els emails: \\n\")\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor que mes es repeteix es:  e , i es repeteix  438561  vegades\n",
      "El valor que menys es repeteix es:  felipe , i es repeteix  21  vegades\n"
     ]
    }
   ],
   "source": [
    "print(\"El valor que mes es repeteix es: \",sums.idxmax(),\", i es repeteix \",sums.max(),\" vegades\")\n",
    "print(\"El valor que menys es repeteix es: \",sums.idxmin(),\", i es repeteix \",sums.min(),\" vegades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3672\n",
       "1    1500\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fitxer csv conté **5172** files, on cada fila representa un correu electronic. \n",
    "\n",
    "Per a cada correu electrònic hi ha **3002** columnes, on la primera columna indica el nom del correu electrònic en format numèric per tal de protegir la privadesa de l'usuari, l'última columna té les etiquetes de predicció on 0 significa que no es spam i 1 significa que si és spam, la resta de **3000** columnes son el nombre de vegades que apareixen les paraules més comunes a tots els correus electrònics.\n",
    "\n",
    "Com veiem tots els nostres atributs son valors numèrics, excepte el primer camp que es un string que com hem dit abans indica l'usuari de l'email.\n",
    "\n",
    "També podem veure que el nostre dataset conté **0** valors nulls.\n",
    "\n",
    "Una vegada visualitzat i analitzat el nostre dataset, podrem dir que la variable objectiu serà **\"Prediction\"** (l'ultim atribut de les mostres), i les variables predictores seran les columnes amb el nombre de vegades que apareix cada paraula (tots els atributs menys el primer \"Email No.\" i l'ultim \"Prediction\").\n",
    "\n",
    "També podem veure que la variable que més apareix en tots els emails es **\"e\"** que apareix un total de **438561** vegades, metre que la que menys apareix es **\"felipe\"** que apareix un total de **21** vegades.\n",
    "\n",
    "Per acabar el nostre dataset té **3672** correus que no són spam i **1500** que si ho son, per tant podem veure hi ha una petita diferencia entre els correus que son spam i els que no ho son , pero no creiem que la diferencia sigui suficient per a dir que les dades no estan balancejades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Realitzarem les transformacions necesaries al nostre dataset per tal de poder utilitzarlo alhora de realitzar el nostre estudi.\n",
    "\n",
    "Com que tenim una gran quantitat de variables predictores, ens es molt complicat eliminar variables segons les correlacions, apart no tendria cap sentit fer-ho ja que cada paraula es important alhora de predir si un email es spam o no.\n",
    "\n",
    "Tampoc podem eliminar valors nuls ja que com hem vist en el data analysis el nostre dataset no en té cap.\n",
    "\n",
    "Un dels canvis que realitzarem serà eliminar la primera columna ja que per a la realització del model no ens serà necessaria ja que el número de correu es una dada irrellevant, el que farem serà posarla com a index del dataframe.\n",
    "\n",
    "Un altre canvi que realitzarem serà la normalització de les dades mitjançant el mètode MinMaxScaler de la llibreria preprocessing de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostrarem les 5 primeres dades del nostre dataset, per veure que efectivament hem normalitzat correctament les dades: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.067055</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.161677</td>\n",
       "      <td>0.080717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.026870</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.046647</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.030032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        the        to       ect       and       for        of         a  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.001054   \n",
       "1  0.038095  0.098485  0.067055  0.067416  0.127660  0.025974  0.053741   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.004215   \n",
       "3  0.000000  0.037879  0.061224  0.000000  0.106383  0.012987  0.026870   \n",
       "4  0.033333  0.045455  0.046647  0.011236  0.106383  0.025974  0.030032   \n",
       "\n",
       "        you       hou        in     ...      connevey  jay  valued  lay  \\\n",
       "0  0.000000  0.000000  0.000000     ...           0.0  0.0     0.0  0.0   \n",
       "1  0.014286  0.161677  0.080717     ...           0.0  0.0     0.0  0.0   \n",
       "2  0.000000  0.000000  0.017937     ...           0.0  0.0     0.0  0.0   \n",
       "3  0.028571  0.059880  0.004484     ...           0.0  0.0     0.0  0.0   \n",
       "4  0.000000  0.053892  0.013453     ...           0.0  0.0     0.0  0.0   \n",
       "\n",
       "   infrastructure  military  allowing        ff  dry  Prediction  \n",
       "0             0.0       0.0       0.0  0.000000  0.0         0.0  \n",
       "1             0.0       0.0       0.0  0.008772  0.0         0.0  \n",
       "2             0.0       0.0       0.0  0.000000  0.0         0.0  \n",
       "3             0.0       0.0       0.0  0.000000  0.0         0.0  \n",
       "4             0.0       0.0       0.0  0.008772  0.0         0.0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Email No.'], axis=1)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "df = pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "\n",
    "print(\"Mostrarem les 5 primeres dades del nostre dataset, per veure que efectivament hem normalitzat correctament les dades: \")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data separation\n",
    "En aquesta fase, separarem les dades que nosaltres volem entrenar en el nostre algoritme, i les separarem de la variable target, per realitzar aquesta fase utilitzarem la funció train_test_split de la llibreria sklearn.\n",
    "\n",
    "Les dades que entrenarem seràn les **3000** columnes que contenen el nombre de vegades que apareix la paraula en els correus, mentre que la nostre variable target serà la ultima variabled el nostre dataset anomenada **\"Predictions\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació de models\n",
    "Models que utiltizarem:\n",
    "- **Regressió logística**\n",
    "- **Random Forest**\n",
    "- **Naive Bayes**\n",
    "- **SVC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressió logística\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97      1134\n",
      "         1.0       0.91      0.95      0.93       418\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1552\n",
      "   macro avg       0.95      0.96      0.95      1552\n",
      "weighted avg       0.96      0.96      0.96      1552\n",
      "\n",
      "Score:  0.9626288659793815\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression(solver='liblinear')\n",
    "model_LR.fit(X_train,y_train)\n",
    "\n",
    "predict_LR = model_LR.predict(X_test)\n",
    "print(classification_report(predict_LR,y_test))\n",
    "\n",
    "print(\"Score: \",model_LR.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96      1156\n",
      "         1.0       0.84      0.93      0.88       396\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1552\n",
      "   macro avg       0.91      0.93      0.92      1552\n",
      "weighted avg       0.94      0.94      0.94      1552\n",
      "\n",
      "Score:  0.9355670103092784\n"
     ]
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier()\n",
    "model_RF.fit(X_train,y_train)\n",
    "\n",
    "predict_RF = model_RF.predict(X_test)\n",
    "print(classification_report(predict_RF,y_test))\n",
    "\n",
    "print(\"Score: \",model_RF.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95      1129\n",
      "         1.0       0.85      0.88      0.87       423\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1552\n",
      "   macro avg       0.90      0.91      0.91      1552\n",
      "weighted avg       0.93      0.93      0.93      1552\n",
      "\n",
      "Score:  0.9259020618556701\n"
     ]
    }
   ],
   "source": [
    "model_NB=MultinomialNB()\n",
    "model_NB.fit(X_train,y_train)\n",
    "\n",
    "predict_NB = model_NB.predict(X_test)\n",
    "print(classification_report(predict_NB,y_test))\n",
    "\n",
    "print(\"Score: \",model_NB.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.72      0.84      1548\n",
      "         1.0       0.01      1.00      0.02         4\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1552\n",
      "   macro avg       0.50      0.86      0.43      1552\n",
      "weighted avg       1.00      0.72      0.83      1552\n",
      "\n",
      "Score:  0.720360824742268\n"
     ]
    }
   ],
   "source": [
    "model_SVC= SVC(C=1.0,kernel='rbf',gamma='auto')\n",
    "model_SVC.fit(X_train,y_train)\n",
    "\n",
    "predict_SVC = model_SVC.predict(X_test)\n",
    "print(classification_report(predict_SVC,y_test))\n",
    "\n",
    "print(\"Score: \",model_SVC.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest apartat mostrarem els seguents atributs dels models entrenats previament:\n",
    "- **Accuracy** del model.\n",
    "- **F1 score** del model.\n",
    "- **RMSE** del model.\n",
    "\n",
    "Realitzarem una grafica per a comparar els resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Regressió Logistica: \n",
      "Accuracy:  96.26288659793815 %\n",
      "F1 SCORE:  93.22429906542057 %\n",
      "RMSE:  0.037371134020618556\n",
      "--------------------------------\n",
      "\n",
      "--------------------------------\n",
      "Random Forest: \n",
      "Accuracy:  93.55670103092784 %\n",
      "F1 SCORE:  88.0095923261391 %\n",
      "RMSE:  0.06443298969072164\n",
      "--------------------------------\n",
      "\n",
      "--------------------------------\n",
      "Naive Bayes: \n",
      "Accuracy:  92.59020618556701 %\n",
      "F1 SCORE:  86.64343786295005 %\n",
      "RMSE:  0.0740979381443299\n",
      "--------------------------------\n",
      "\n",
      "--------------------------------\n",
      "SVC: \n",
      "Accuracy:  72.0360824742268 %\n",
      "F1 SCORE:  1.809954751131222 %\n",
      "RMSE:  0.27963917525773196\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------\")\n",
    "\n",
    "print(\"Regressió Logistica: \")\n",
    "print (\"Accuracy: \", accuracy_score(y_test, predict_LR)*100, \"%\")\n",
    "print (\"F1 SCORE: \", f1_score(y_test, predict_LR)*100, \"%\")\n",
    "print (\"RMSE: \", mean_squared_error(y_test, predict_LR))\n",
    "print(\"--------------------------------\\n\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"Random Forest: \")\n",
    "print (\"Accuracy: \", accuracy_score(y_test, predict_RF)*100, \"%\")\n",
    "print (\"F1 SCORE: \", f1_score(y_test, predict_RF)*100, \"%\")\n",
    "print (\"RMSE: \", mean_squared_error(y_test, predict_RF))\n",
    "print(\"--------------------------------\\n\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"Naive Bayes: \")\n",
    "print (\"Accuracy: \", accuracy_score(y_test, predict_NB)*100, \"%\")\n",
    "print (\"F1 SCORE: \", f1_score(y_test, predict_NB)*100, \"%\")\n",
    "print (\"RMSE: \", mean_squared_error(y_test, predict_NB))\n",
    "print(\"--------------------------------\\n\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"SVC: \")\n",
    "print (\"Accuracy: \", accuracy_score(y_test, predict_SVC)*100, \"%\")\n",
    "print (\"F1 SCORE: \", f1_score(y_test, predict_SVC)*100, \"%\")\n",
    "print (\"RMSE: \", mean_squared_error(y_test, predict_SVC))\n",
    "print(\"--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"red\",\"blue\",\"green\",\"purple\"]\n",
    "lr_acc = accuracy_score(y_test, predict_LR)\n",
    "rf_acc = accuracy_score(y_test, predict_RF)\n",
    "nb_acc = accuracy_score(y_test, predict_NB)\n",
    "svc_acc = accuracy_score(y_test, predict_SVC)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylabel(\"Precision %\")\n",
    "plt.xlabel(\"Algoritmos\")\n",
    "sns.barplot(x=['Regressió logística', 'Random Forest' ,'Naive Bayes','SVC'],y=[lr_acc*100,rf_acc*100,nb_acc*100,svc_acc*100], palette=colors )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusions\n",
    "Si comparem els resultats obtinguts dels diferents models, podem veure que el millor classificador de tots es el model de regressió logística, seguit per random forest i naive bayes amb una puntuació molt semblant, i per acabar el pitjor classificador és SVC.\n",
    "\n",
    "- El millor classificador és el model de **regressió logística** ja que es un dels millors models quan es tracta d'un problema de regressió binària (quan la variable predictora pot adoptar dos valors, en aquest cas 0 o 1).\n",
    "- Com podiem esperar el **random forest** també té una bona puntuació en aquest problema ja que combinem la presició de 100 arbres ja que com a default n_estimators és 100, és per aixó que genera un bon model.\n",
    "- **Naive Bayes**, és el millor classificador per a problemes de text classification, no obstant el rendiment d'aquest model no supera al model de Regressió Logística o Random forest.\n",
    "- Per a acabar el pitjor model dels 4 és **SVC**, ja que aquest model no es gairé bó per a un problema de classificació binària, sinò que és millor per a problemes de grans dimensions espacials.\n",
    "\n",
    "Per a concloure, si tinguessim que escollir els millors models del nostre estudi serien Regressió Logística, Random Forest i Naive Bayes, qualsevol dels 3 és un bon model per al nostre problema de classificació.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
